# RAG Chatbot MCP Platform

> **âš ï¸ Under Construction**  
> This project is currently under active development. Features, APIs, and documentation may change.

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![MCP](https://img.shields.io/badge/MCP-2025--06--18-green.svg)](https://modelcontextprotocol.io/)
[![Claude Desktop](https://img.shields.io/badge/Claude-Desktop-orange.svg)](https://claude.ai/download)
[![License](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](LICENSE)

**AI-Orchestrated Retrieval-Augmented Generation Platform using Model Context Protocol**

Build intelligent, context-aware chatbots that leverage your own data through natural language interactions. This platform provides 7 specialized MCP servers with 35+ tools for complete RAG pipeline orchestration.


![Overview](./unnamed (2).png)


---

## ğŸš€ Quick Start

### Option 1: Streamlit Web App (Recommended for Beginners)

```bash
# 1. Clone repository
git clone https://github.com/your-org/rag-chatbot-mcp.git
cd rag-chatbot-mcp

# 2. Install dependencies
pip install -r requirements.txt
pip install -r ui/requirements.txt

# 3. Start ChromaDB in Docker (optional but recommended)
docker-compose up -d chromadb
# Or use: .\scripts\start_chromadb.ps1 (Windows) or ./scripts/start_chromadb.sh (Linux/Mac)

# 4. Start Ollama (in a separate terminal)
ollama serve
ollama pull llama3.2:1b  # or tinyllama

# 5. Run Streamlit app
cd ui/streamlit-app
streamlit run app.py
```

The app will open at `http://localhost:8501`. See [UI README](ui/README.md) for detailed instructions.

**Note:** ChromaDB will automatically connect to Docker if available, or use local/mock mode otherwise.

### Option 2: Jupyter Notebook (Recommended for Learning)

```bash
# 1. Clone repository
git clone https://github.com/your-org/rag-chatbot-mcp.git
cd rag-chatbot-mcp

# 2. Install dependencies
pip install -r requirements.txt
pip install -r ui/requirements.txt

# 3. Start ChromaDB in Docker (optional but recommended)
docker-compose up -d chromadb
# Or use: .\scripts\start_chromadb.ps1 (Windows) or ./scripts/start_chromadb.sh (Linux/Mac)

# 4. Start Ollama (in a separate terminal)
ollama serve
ollama pull llama3.2:1b

# 5. Start Jupyter
jupyter notebook

# 6. Open ui/jupyter-notebook/rag_pipeline_exercise.ipynb
```

**Note:** ChromaDB will automatically connect to Docker if available, or use local/mock mode otherwise.

### Option 3: Claude Desktop Integration

```bash
# 1. Clone repository
git clone https://github.com/your-org/rag-chatbot-mcp.git
cd rag-chatbot-mcp

# 2. Install dependencies
pip install -r requirements.txt

# 3. Configure Claude Desktop (7 MCP servers)
# macOS:
cp desktop-configs/claude_desktop_config.json \
   ~/Library/Application\ Support/Claude/claude_desktop_config.json

# Linux:
cp desktop-configs/claude_desktop_config.json \
   ~/.config/Claude/claude_desktop_config.json

# Windows:
# Copy desktop-configs/claude_desktop_config.json to:
# %APPDATA%\Claude\claude_desktop_config.json

# 4. Restart Claude Desktop
# 5. Verify servers are connected in Claude Desktop settings
```

**Prerequisites:** 
- **Python 3.11 or 3.12** (recommended) - Python 3.14+ has ChromaDB compatibility issues
- **Docker Desktop** (recommended for ChromaDB) - [Install Docker Desktop](https://www.docker.com/products/docker-desktop)
- **Ollama** (for UI) - [Install Ollama](https://ollama.ai)
- Claude Desktop (optional, for MCP integration)
- 16GB RAM, 20GB disk

**Quick Setup:**
```bash
# 1. Start ChromaDB in Docker (recommended)
docker-compose up -d chromadb

# 2. Start Ollama
ollama serve
ollama pull llama3.2:1b
```

**Note:** If using Python 3.14+, ChromaDB will use mock mode (works for testing). For production, use Python 3.11 or 3.12. See [Troubleshooting](docker/TROUBLESHOOTING.md) for details.

---

## ğŸ“Š System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           USER INTERFACES                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸŒ Streamlit Chat UI    â”‚   ğŸ““ Jupyter Notebook   â”‚   ğŸ’¬ Claude Desktop    â”‚
â”‚     (Web Interface)      â”‚   (Data Science)        â”‚      (Local STDIO)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                        â”‚                         â”‚
             â–¼                        â–¼                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        AI ORCHESTRATION LAYER                                â”‚
â”‚                    ğŸ¤– Claude API (MCP Client Support)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                            â–¼                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DATA INGESTIONâ”‚          â”‚   RETRIEVAL   â”‚          â”‚   GENERATION  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤          â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤          â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ mcp-chunker   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ mcp-retriever â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ mcp-generator â”‚
â”‚ mcp-embeddingsâ”‚          â”‚ mcp-reranker  â”‚          â”‚               â”‚
â”‚ mcp-datasourcesâ”‚         â”‚ mcp-vectorstoreâ”‚         â”‚               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                            â”‚                            â”‚
        â–¼                            â–¼                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           DATA LAYER                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   ğŸ“„ Documents    â”‚   ğŸ”¢ Vector Store   â”‚   ğŸ“Š Indexes   â”‚   ğŸ’¾ Cache      â”‚
â”‚   (PDF, TXT, MD)  â”‚   (ChromaDB/FAISS)  â”‚   (BM25/Hybrid)â”‚   (Redis/Local) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ MCP Servers Overview

| Server | Tools | Status | Description |
|--------|-------|--------|-------------|
| **mcp-vectorstore** | 6 | âœ… Production | Vector database operations, similarity search, index management |
| **mcp-retriever** | 5 | âœ… Production | Document retrieval, hybrid search, metadata filtering |
| **mcp-embeddings** | 4 | âœ… Production | Embedding generation (OpenAI, local models, batch processing) |
| **mcp-chunker** | 5 | âœ… Production | Document chunking, text splitting, preprocessing |
| **mcp-reranker** | 4 | âœ… Production | Result reranking, cross-encoder scoring, diversity filtering |
| **mcp-generator** | 5 | âœ… Production | Response generation, context assembly, prompt templates |
| **mcp-datasources** | 6 | âœ… Production | External connectors (files, URLs, APIs, databases) |

**Total: 7 servers, 35+ tools**

---

## ğŸ“ Project Structure

```
rag-chatbot-mcp/
â”œâ”€â”€ README.md                           # This file
â”œâ”€â”€ LICENSE                             # Apache 2.0
â”œâ”€â”€ ACKNOWLEDGMENTS.md                  # Credits and references
â”œâ”€â”€ .gitignore                          # Git ignore patterns
â”‚
â”œâ”€â”€ architecture/                       # System design documentation
â”‚   â”œâ”€â”€ README.md                       # Architecture overview
â”‚   â”œâ”€â”€ diagrams/                       # Mermaid diagrams, architecture images
â”‚   â””â”€â”€ rag-pipeline/                   # RAG pipeline detailed design
â”‚
â”œâ”€â”€ data/                               # Data files and samples
â”‚   â”œâ”€â”€ sample-data/                    # Example documents for testing
â”‚   â”œâ”€â”€ embeddings/                     # Pre-computed embeddings
â”‚   â””â”€â”€ indexes/                        # Vector indexes
â”‚
â”œâ”€â”€ desktop-configs/                    # Claude Desktop configurations
â”‚   â””â”€â”€ claude_desktop_config.json      # MCP server configuration
â”‚
â”œâ”€â”€ docs/                               # Documentation
â”‚   â”œâ”€â”€ operations/                     # Operations guides
â”‚   â”œâ”€â”€ deployment/                     # Deployment instructions
â”‚   â””â”€â”€ user-guides/                    # User documentation
â”‚
â”œâ”€â”€ infrastructure/                     # Deployment infrastructure
â”‚   â”œâ”€â”€ gcp/                            # Google Cloud Platform setup
â”‚   â””â”€â”€ local/                          # Local development setup
â”‚
â”œâ”€â”€ scripts/                            # Utility scripts
â”‚   â”œâ”€â”€ setup.sh                        # Initial setup
â”‚   â””â”€â”€ deploy.sh                       # Deployment automation
â”‚
â”œâ”€â”€ servers/                            # MCP Server implementations
â”‚   â”œâ”€â”€ mcp-vectorstore/                # Vector database server
â”‚   â”œâ”€â”€ mcp-retriever/                  # Retrieval server
â”‚   â”œâ”€â”€ mcp-embeddings/                 # Embeddings server
â”‚   â”œâ”€â”€ mcp-chunker/                    # Document chunking server
â”‚   â”œâ”€â”€ mcp-reranker/                   # Reranking server
â”‚   â”œâ”€â”€ mcp-generator/                  # Response generation server
â”‚   â””â”€â”€ mcp-datasources/                # Data source connectors
â”‚
â”œâ”€â”€ shared/                             # Shared utilities
â”‚   â”œâ”€â”€ utils/                          # Common utilities
â”‚   â”œâ”€â”€ models/                         # Data models
â”‚   â””â”€â”€ config/                         # Configuration management
â”‚
â”œâ”€â”€ tests/                              # Test suites
â”‚   â”œâ”€â”€ integration/                    # Integration tests
â”‚   â””â”€â”€ manual_testing/                 # Manual testing guides
â”‚
â””â”€â”€ ui/                                 # User interfaces
    â”œâ”€â”€ streamlit-app/                  # Web chat interface (app.py)
    â”œâ”€â”€ jupyter-notebook/              # Notebook interface (rag_pipeline_exercise.ipynb)
    â”œâ”€â”€ README.md                       # UI components documentation
    â”œâ”€â”€ QUICKSTART.md                   # Quick start guide
    â””â”€â”€ requirements.txt                # UI-specific dependencies
```

---

## ğŸ¯ Who is this For?

### ğŸ”¬ AI/ML Engineers
*You want to build production RAG systems with modular, testable components*

**What you can do:**
- Build custom RAG pipelines with interchangeable components
- Experiment with different embedding models and retrieval strategies
- Implement advanced techniques (HyDE, step-back prompting, multi-query)
- Scale from prototype to production with the same architecture
- Use interactive UIs (Streamlit/Jupyter) for rapid prototyping

**Quick Start:**
1. [Streamlit App](ui/README.md#streamlit-app) - Interactive web interface for testing
2. [Jupyter Notebook](ui/README.md#jupyter-notebook) - Step-by-step pipeline exploration
3. [RAG Pipeline Guide](tests/manual_testing/RAG-Pipeline/README.md) - Detailed pipeline docs
4. [Sample Data](data/sample-data/README.md) - Example documents
5. [Server APIs](servers/README.md) - Complete API reference

---

### ğŸ’» MCP Developers
*You want to learn MCP patterns or extend the platform*

**What you can learn:**
- MCP server architecture and best practices
- Testing patterns (unit, integration, functional)
- Tool design for LLM orchestration
- Production deployment strategies

**Development Resources:**
- [Architecture Deep Dive](architecture/README.md)
- [Server Implementation Guide](docs/development/SERVER_GUIDE.md)
- [Testing Guide](tests/manual_testing/Solution-Testing/MANUAL_TESTING_GUIDE.md)

---

### ğŸ› ï¸ Software Engineers
*You want to deploy, integrate, or scale this system*

**Deployment Scenarios:**

| Environment | Setup | Resources | Use Case |
|-------------|-------|-----------|----------|
| **Local Development** | MacOS/Linux + Claude Desktop | 16GB RAM, 20GB disk | Development, testing |
| **Cloud Research** | GCP Cloud Run | Custom (scalable) | Production, multi-user |
| **Enterprise** | Kubernetes + GPU | 32GB+ RAM | High-throughput RAG |

**Infrastructure Resources:**
- [GCP Deployment Guide](infrastructure/gcp/README.md)
- [Local Setup](infrastructure/local/README.md)
- [Claude Desktop Config](desktop-configs/README.md)

---

### ğŸ“ Students & Educators
*You want to learn RAG concepts hands-on*

**Why this is perfect for teaching:**
- âœ… **Modular design** - Learn each RAG component separately
- âœ… **Sample data included** - Ready to run examples
- âœ… **Well-documented** - Step-by-step guides with expected outputs
- âœ… **Low cost** - Run locally with free/cheap models
- âœ… **Interactive UIs** - Streamlit app and Jupyter notebook for hands-on learning

**Educational Topics:**
- Vector embeddings and similarity search
- Document chunking strategies
- Retrieval and reranking techniques
- Prompt engineering for RAG
- Evaluation and metrics

**Quick Start for Students:**
1. [Streamlit App](ui/README.md#streamlit-app) - Visual, interactive interface
2. [Jupyter Notebook](ui/README.md#jupyter-notebook) - Step-by-step exploration
3. [Sample Data](data/sample-data/) - Ready-to-use documents

---

## ğŸ’° Cost Analysis

| Mode | Time | Cost | Use Case |
|------|------|------|----------|
| **Demo (Local UI)** | 5-10 min | **$0** | Testing with Streamlit/Jupyter + Ollama |
| **Demo (Cloud)** | 5-10 min | ~$0.10 | Testing with OpenAI embeddings + Claude API |
| **Development** | 30-60 min | ~$1-2 | Building features |
| **Production** | Continuous | ~$10-50/day | Deployed chatbot |

*Local UI mode (Streamlit/Jupyter + Ollama + sentence-transformers) has $0 operational cost. Cloud mode uses OpenAI embeddings + Claude API.*

---

## ğŸƒ Example Usage

### Using the Streamlit Web App

1. **Load Documents**: Click "ğŸ“¥ Load Sample Documents" in the Document Loading tab
2. **Index Documents**: Click "ğŸ”¨ Index Documents" to chunk, embed, and store documents
3. **Query**: Switch to Query & Chat tab and ask questions like:
   - "What is RAG?"
   - "How does RAG work?"
   - "What are the benefits of RAG?"

### Using the Jupyter Notebook

Run cells sequentially to see each step of the RAG pipeline:
- Load sample documents
- Chunk documents with different strategies
- Generate embeddings
- Store in vector database
- Query and retrieve relevant chunks
- Generate responses with Ollama

### Natural Language RAG Operations (Claude Desktop)

```
User: "Load all the PDF documents from my /docs folder"
Claude: [Uses mcp-datasources to load files, mcp-chunker to process them]

User: "Create embeddings and index them"
Claude: [Uses mcp-embeddings to generate vectors, mcp-vectorstore to index]

User: "What does the documentation say about authentication?"
Claude: [Uses mcp-retriever for search, mcp-reranker for relevance, mcp-generator for response]

User: "Show me the most similar documents to this query"
Claude: [Uses mcp-vectorstore for similarity search, returns ranked results]
```

---

## ğŸ”§ Configuration

### Claude Desktop Configuration

The platform includes **7 MCP servers** configured for Claude Desktop. Copy the configuration file:

```bash
cp desktop-configs/claude_desktop_config.json \
   ~/Library/Application\ Support/Claude/claude_desktop_config.json
```

**Configured Servers:**
1. `rag-vectorstore` - Vector database operations
2. `rag-embeddings` - Embedding generation
3. `rag-retriever` - Document retrieval
4. `rag-chunker` - Document chunking
5. `rag-reranker` - Result reranking
6. `rag-generator` - Response generation
7. `rag-datasources` - Data source connectors

**Example Configuration:**
```json
{
  "mcpServers": {
    "rag-vectorstore": {
      "command": "python",
      "args": ["-m", "servers.mcp-vectorstore.src.server"],
      "cwd": "${workspaceFolder}"
    },
    "rag-embeddings": {
      "command": "python",
      "args": ["-m", "servers.mcp-embeddings.src.server"],
      "cwd": "${workspaceFolder}"
    }
    // ... 5 additional servers (see desktop-configs/claude_desktop_config.json)
  }
}
```

See `desktop-configs/claude_desktop_config.json` for the complete configuration with all 7 servers and environment variables.

---

## ğŸ“š Documentation

| Document | Description |
|----------|-------------|
| [UI Components Guide](ui/README.md) | **NEW!** Streamlit app and Jupyter notebook usage |
| [UI Quick Start](ui/QUICKSTART.md) | **NEW!** Quick start guide for UI components |
| [ChromaDB Docker Setup](docker/README.md) | **NEW!** Running ChromaDB in Docker |
| [Architecture Overview](architecture/README.md) | System design and data flow |
| [RAG Pipeline Guide](architecture/rag-pipeline/README.md) | Detailed pipeline documentation |
| [Server Reference](servers/README.md) | Complete API documentation |
| [Deployment Guide](docs/deployment/README.md) | Production deployment |
| [User Guide](docs/user-guides/README.md) | End-user documentation |
| [Testing Guide](tests/manual_testing/Solution-Testing/MANUAL_TESTING_GUIDE.md) | Testing procedures |

---

## ğŸ¤ Contributing

Contributions welcome! Priority areas include:
- New embedding model integrations
- Additional vector store backends
- Advanced retrieval strategies
- UI improvements

See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

---

## ğŸ“„ License

Apache 2.0 - See [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgments

This project is inspired by the [precision-medicine-mcp](https://github.com/lynnlangit/precision-medicine-mcp) project structure. See [ACKNOWLEDGMENTS.md](ACKNOWLEDGMENTS.md) for full credits.
